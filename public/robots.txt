# Robots.txt for UniHome Kit
# https://www.uni-home-kit.au
# Last updated: 2026-02-02

# Default: Allow all crawlers
User-agent: *
Allow: /

# Sitemap location
Sitemap: https://www.uni-home-kit.au/sitemap.xml

# Disallow common non-content paths
Disallow: /src/
Disallow: /node_modules/

# ========================================
# AI Search Engine Crawlers
# ========================================
# These rules explicitly allow AI-powered search engines
# to crawl and index your content for AI search results.
# Remove any of these if you prefer to block specific AI crawlers.

# OpenAI / ChatGPT
User-agent: GPTBot
Allow: /

User-agent: ChatGPT-User
Allow: /

# Google AI (Bard, Gemini, AI Overviews)
User-agent: Google-Extended
Allow: /

# Perplexity AI
User-agent: PerplexityBot
Allow: /

# Anthropic / Claude
User-agent: Claude-Web
Allow: /
User-agent: anthropic-ai
Allow: /

# Meta AI
User-agent: FacebookBot
Allow: /

# Microsoft / Bing AI (Copilot)
User-agent: Bingbot
Allow: /

# Common Crawl (used by many AI training datasets)
User-agent: CCBot
Allow: /

# Cohere AI
User-agent: cohere-ai
Allow: /

# You.com AI
User-agent: YouBot
Allow: /
